{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54d6548f-b305-46f7-8216-3f4325723b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import re\n",
    "\n",
    "\n",
    "def pull_craigslist_links():\n",
    "    \n",
    "    # Define the URLs\n",
    "    craigslist_base_url = 'https://losangeles.craigslist.org/search/santa-monica-ca/apa?lat=34.0315&lon=-118.461&max_bathrooms=1&max_bedrooms=1&min_bathrooms=1&min_bedrooms=1&postedToday=1&search_distance=3.6#search=1'\n",
    "    craigslist_search_first_page_url = 'https://losangeles.craigslist.org/search/santa-monica-ca/apa?lat=34.0315&lon=-118.461&max_bathrooms=1&max_bedrooms=1&min_bathrooms=1&min_bedrooms=1&postedToday=1&search_distance=3.6#search=1~list~0~0'\n",
    "    chrome_driver_path = 'chromedriver-mac-arm64/chromedriver'\n",
    "\n",
    "    # Create the access_beautiful_soup function\n",
    "    def access_beautiful_soup(url):\n",
    "        # Call a get instance with the URL\n",
    "        response = requests.get(url)\n",
    "    \n",
    "        # Sleep in order to not overwhelm servers\n",
    "        time.sleep(5 + 10 * random.random())\n",
    "    \n",
    "        # Find all the listings links on the page\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "        return soup\n",
    "\n",
    "    # Function to return the number of posts at a given time\n",
    "    def get_postings_count(website, path):\n",
    "        \n",
    "        # # prevent a window from opening in Selenium\n",
    "        options = Options()\n",
    "        options.add_argument('--headless')\n",
    "        options.add_argument('--disable-gpu')\n",
    "        \n",
    "        # set up the Chrome driver path for Selenium usage\n",
    "        service = Service(path)\n",
    "        driver = webdriver.Chrome(service=service, options=options)\n",
    "    \n",
    "        # Call a \"get\" instance of the initial Craigslist page to initialize Selenium\n",
    "        driver.get(website)\n",
    "    \n",
    "        # Put in a function stopper to let the page render.\n",
    "        # 15 seconds should be plenty, but if the result is coming back as\n",
    "        # \"no results,\" the first troubleshoot would be to increase this time\n",
    "        # to see if that fixes it.\n",
    "        time.sleep(15)  \n",
    "    \n",
    "        try:\n",
    "    \n",
    "            # Use JavaScript to set up a script to return the postings count\n",
    "            postings_count_script = \"\"\"\n",
    "                var postingsDiv = document.querySelector('.cl-count-save-bar > div');\n",
    "                return postingsDiv ? postingsDiv.textContent : 'Postings count not found';\n",
    "            \"\"\"\n",
    "    \n",
    "            # Execute the script to get the post count and return it\n",
    "            postings_count = driver.execute_script(postings_count_script)\n",
    "    \n",
    "            # Quit Selenium\n",
    "            driver.quit()\n",
    "    \n",
    "            # Return the postings count\n",
    "            return postings_count\n",
    "        except Exception as e:\n",
    "            print(f\"Error encountered: {e}\")\n",
    "\n",
    "    # Call the get_postings_count function\n",
    "    postings_count = get_postings_count(craigslist_search_first_page_url, chrome_driver_path)\n",
    "\n",
    "    # Function to calculate the number of pages for us to loop through\n",
    "    def calculate_pages_from_postings(postings_count_str):\n",
    "        \n",
    "        # Remove commas and extract the numerical part of the string\n",
    "        num_postings = int(postings_count_str.replace(\" postings\", \"\").replace(\",\", \"\"))\n",
    "        \n",
    "        # 120 posts per page\n",
    "        postings_per_page = 120\n",
    "        \n",
    "        # Calculate the number of pages needed to display all postings, accounting for remainder\n",
    "        num_pages = -(-num_postings // postings_per_page)  \n",
    "        \n",
    "        return num_pages\n",
    "\n",
    "    # Call the calculate_pages_from_postings function\n",
    "    number_of_pages = calculate_pages_from_postings(postings_count)\n",
    "\n",
    "    # Extract the links from each of the pages\n",
    "    def extract_listing_links(path, base_url, number_of_pages):\n",
    "        all_listing_links = []\n",
    "        \n",
    "        for page_number in range(number_of_pages):\n",
    "            page_url = f'{base_url}~list~{page_number}~0'\n",
    "            \n",
    "            # prevent a window from opening in Selenium\n",
    "            options = Options()\n",
    "            options.add_argument('--headless')\n",
    "            options.add_argument('--disable-gpu')\n",
    "            \n",
    "            # set up the Chrome driver path for Selenium usage\n",
    "            service = Service(path)\n",
    "            driver = webdriver.Chrome(service=service, options=options)\n",
    "            \n",
    "            driver.get(page_url)\n",
    "            \n",
    "            # Wait for the listings to be present\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"li.cl-search-result.cl-search-view-mode-list\"))\n",
    "            )\n",
    "            # Now that the page is loaded, find all the `a` tags within the listings\n",
    "            listing_links = [a.get_attribute('href') for a in driver.find_elements(By.CSS_SELECTOR, \"li.cl-search-result.cl-search-view-mode-list a\")]\n",
    "    \n",
    "            all_listing_links.extend(listing_links)\n",
    "    \n",
    "            driver.quit()\n",
    "            \n",
    "        return all_listing_links\n",
    "\n",
    "    all_links = extract_listing_links(chrome_driver_path, craigslist_base_url, number_of_pages)\n",
    "\n",
    "    # Convert the list of links to a DataFrame\n",
    "    links_df = pd.DataFrame(all_links, columns=['URL'])\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    links_df.to_csv('craigslist_links.csv', index=False)\n",
    "\n",
    "    print(\"CSV file has been created successfully.\")\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     pull_craigslist_links()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88c4aa34-78b5-4ebf-bf86-a2914d8a9a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "pull_craigslist_links()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
