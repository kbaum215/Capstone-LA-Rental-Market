{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1b3ac93-0232-48cb-ba98-93a7617660d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ba4fb5-d5b3-40c6-974c-7c4b0687763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_craigslist_links():\n",
    "    # Define the URLs\n",
    "    craigslist_base_url = 'https://losangeles.craigslist.org/search/santa-monica-ca/apa?lat=34.0315&lon=-118.461&max_bathrooms=1&max_bedrooms=1&min_bathrooms=1&min_bedrooms=1&postedToday=1&search_distance=3.6#search=1'\n",
    "    craigslist_search_first_page_url = 'https://losangeles.craigslist.org/search/santa-monica-ca/apa?lat=34.0315&lon=-118.461&max_bathrooms=1&max_bedrooms=1&min_bathrooms=1&min_bedrooms=1&postedToday=1&search_distance=3.6#search=1~list~0~0'\n",
    "    chrome_driver_path = 'Other_Material/chromedriver-mac-arm64/chromedriver'\n",
    "\n",
    "    # Create the access_beautiful_soup function\n",
    "    def access_beautiful_soup(url):\n",
    "        # Call a get instance with the URL\n",
    "        response = requests.get(url)\n",
    "    \n",
    "        # Sleep in order to not overwhelm servers\n",
    "        time.sleep(5 + 10 * random.random())\n",
    "    \n",
    "        # Find all the listings links on the page\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "        return soup\n",
    "\n",
    "    # Function to return the number of posts at a given time\n",
    "    def get_postings_count(website, path):\n",
    "        \n",
    "        # # prevent a window from opening in Selenium\n",
    "        options = Options()\n",
    "        options.add_argument('--headless')\n",
    "        options.add_argument('--disable-gpu')\n",
    "        \n",
    "        # set up the Chrome driver path for Selenium usage\n",
    "        service = Service(path)\n",
    "        driver = webdriver.Chrome(service=service, options=options)\n",
    "    \n",
    "        # Call a \"get\" instance of the initial Craigslist page to initialize Selenium\n",
    "        driver.get(website)\n",
    "    \n",
    "        # Put in a function stopper to let the page render.\n",
    "        # 15 seconds should be plenty, but if the result is coming back as\n",
    "        # \"no results,\" the first troubleshoot would be to increase this time\n",
    "        # to see if that fixes it.\n",
    "        time.sleep(15)  \n",
    "    \n",
    "        try:\n",
    "    \n",
    "            # Use JavaScript to set up a script to return the postings count\n",
    "            postings_count_script = \"\"\"\n",
    "                var postingsDiv = document.querySelector('.cl-count-save-bar > div');\n",
    "                return postingsDiv ? postingsDiv.textContent : 'Postings count not found';\n",
    "            \"\"\"\n",
    "    \n",
    "            # Execute the script to get the post count and return it\n",
    "            postings_count = driver.execute_script(postings_count_script)\n",
    "    \n",
    "            # Quit Selenium\n",
    "            driver.quit()\n",
    "    \n",
    "            # Return the postings count\n",
    "            return postings_count\n",
    "        except Exception as e:\n",
    "            print(f\"Error encountered: {e}\")\n",
    "\n",
    "    # Call the get_postings_count function\n",
    "    postings_count = get_postings_count(craigslist_search_first_page_url, chrome_driver_path)\n",
    "\n",
    "    # Function to calculate the number of pages for us to loop through\n",
    "    def calculate_pages_from_postings(postings_count_str):\n",
    "        \n",
    "        # Remove commas and extract the numerical part of the string\n",
    "        num_postings = int(postings_count_str.replace(\" postings\", \"\").replace(\",\", \"\"))\n",
    "        \n",
    "        # 120 posts per page\n",
    "        postings_per_page = 120\n",
    "        \n",
    "        # Calculate the number of pages needed to display all postings, accounting for remainder\n",
    "        num_pages = -(-num_postings // postings_per_page)  \n",
    "        \n",
    "        return num_pages\n",
    "\n",
    "    # Call the calculate_pages_from_postings function\n",
    "    number_of_pages = calculate_pages_from_postings(postings_count)\n",
    "\n",
    "    # Extract the links from each of the pages\n",
    "    def extract_listing_links(path, base_url, number_of_pages):\n",
    "        all_listing_links = []\n",
    "        \n",
    "        for page_number in range(number_of_pages):\n",
    "            page_url = f'{base_url}~list~{page_number}~0'\n",
    "            \n",
    "            # prevent a window from opening in Selenium\n",
    "            options = Options()\n",
    "            options.add_argument('--headless')\n",
    "            options.add_argument('--disable-gpu')\n",
    "            \n",
    "            # set up the Chrome driver path for Selenium usage\n",
    "            service = Service(path)\n",
    "            driver = webdriver.Chrome(service=service, options=options)\n",
    "            \n",
    "            driver.get(page_url)\n",
    "            \n",
    "            # Wait for the listings to be present\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"li.cl-search-result.cl-search-view-mode-list\"))\n",
    "            )\n",
    "            # Now that the page is loaded, find all the `a` tags within the listings\n",
    "            listing_links = [a.get_attribute('href') for a in driver.find_elements(By.CSS_SELECTOR, \"li.cl-search-result.cl-search-view-mode-list a\")]\n",
    "    \n",
    "            all_listing_links.extend(listing_links)\n",
    "    \n",
    "            driver.quit()\n",
    "            \n",
    "        return all_listing_links\n",
    "\n",
    "    all_links = extract_listing_links(chrome_driver_path, craigslist_base_url, number_of_pages)\n",
    "\n",
    "    # Convert the list of links to a DataFrame\n",
    "    links_df = pd.DataFrame(all_links, columns=['URL'])\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    links_df.to_csv('craigslist_links.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "114fce0a-56bf-4da1-a24b-ae908d71c250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_craigslist_rates_from_links():\n",
    "\n",
    "    # Initialize the DataFrame\n",
    "    df_columns = [\"Title\", \"Price\", \"Bedrooms\", \"Square Feet\", \"Full Address\"]\n",
    "    todays_listings_df = pd.DataFrame(columns=df_columns)\n",
    "\n",
    "    # Set up links_and_soups dict to be used in pair_links_and_soups function\n",
    "    links_and_soups = {}\n",
    "\n",
    "    # Function to pair links with soup content\n",
    "    def pair_links_and_soups(list_of_links):\n",
    "        for link in list_of_links:\n",
    "            the_soup = access_beautiful_soup(link)\n",
    "            links_and_soups[link] = the_soup\n",
    "\n",
    "    # Call pair_links_and_soups\n",
    "    pair_links_and_soups(all_links)\n",
    "\n",
    "    # Define your master list of attributes\n",
    "    master_attributes = [\n",
    "        \"Title\", \"Price\", \"Bedrooms\", \"Square Feet\", \"Full Address\", \"monthly\",\n",
    "        \"apartment\", \"cats are OK - purrr\", \"dogs are OK - wooof\", \"laundry on site\",\n",
    "        \"air conditioning\", \"off-street parking\", \"EV charging\", \"w/d in unit\",\n",
    "        \"carport\", \"no smoking\", \"attached garage\", \"detached garage\", \"laundry in bldg\",\n",
    "        \"Fee Needed To Apply\", \"wheelchair accessible\", \"no parking\", \"furnished\",\n",
    "        \"street parking\", \"no laundry on site\", \"house\", \"w/d hookups\", \"date_added\"\n",
    "    ]\n",
    "\n",
    "    # Function to initialize the DataFrame with all required columns\n",
    "    def initialize_dataframe():\n",
    "        # Create a DataFrame with all columns initialized to None or a suitable default\n",
    "        return pd.DataFrame(columns=master_attributes)\n",
    "\n",
    "    # Function to create a new entry for the DataFrame\n",
    "    def create_new_entry(data):\n",
    "        return {attr: data.get(attr, 0) if attr not in ['Title', \n",
    "                                                        'Price', \n",
    "                                                        'Bedrooms', \n",
    "                                                        'Square Feet', \n",
    "                                                        'Full Address', \n",
    "                                                        'date_added'] else data.get(attr, 0) for attr in master_attributes}\n",
    "    # Set up global attribute counts dict\n",
    "    global_attribute_counts = {}\n",
    "\n",
    "    # Define the count_attributes_function to view all the attributes used in apartment listings\n",
    "    def process_attributes(the_soup):\n",
    "        attribute_search = the_soup.find_all('div', class_='attr')\n",
    "        attributes = []\n",
    "        fee_needed = 0  # Initialize a flag for fees\n",
    "    \n",
    "        fee_pattern = re.compile(r'\\b\\d+\\b')  # Regex to identify fee-related attributes\n",
    "    \n",
    "        for listing in attribute_search:\n",
    "            value_span = listing.find('span', class_='valu')\n",
    "            if value_span:\n",
    "                attribute = value_span.text.strip()\n",
    "                global_attribute_counts[attribute] = global_attribute_counts.get(attribute, 0) + 1 \n",
    "                if fee_pattern.search(attribute):  # Check if attribute suggests a fee\n",
    "                    fee_needed = 1\n",
    "                else:\n",
    "                    attributes.append(attribute)  # Only add non-fee attributes to the list\n",
    "    \n",
    "        return attributes, fee_needed\n",
    "\n",
    "    # Run process_attributes using the info in the links_and_soups dictionary\n",
    "    for link, soup in links_and_soups.items():\n",
    "        attributes = process_attributes(soup)\n",
    "\n",
    "    # Storing the object results in a variable called \"raw_attributes\" \n",
    "    raw_attributes = global_attribute_counts\n",
    "\n",
    "    # Function to group together fee related attributes\n",
    "    def clean_up_the_fees(attributes_dictionary):\n",
    "        \n",
    "        # Initialize a count for \"Fees Needed To Apply Key\"\n",
    "        fees_needed_to_apply = 0\n",
    "    \n",
    "        # Set up a Regex to identify keys containing integers\n",
    "        # We will use the re package to do this\n",
    "        fee_pattern = re.compile(r'\\b\\d+\\b')\n",
    "    \n",
    "        # Iterate through the dictionary, summing up counts for fee-related attributes\n",
    "        for key, value in raw_attributes.items():\n",
    "            if fee_pattern.search(key):\n",
    "                fees_needed_to_apply += value\n",
    "        \n",
    "        # Update the dictionary and add in a key called \"Fee Needed To Apply\"\n",
    "        cleaned_attributes = {key: value for key, value in raw_attributes.items() if not fee_pattern.search(key)}\n",
    "        cleaned_attributes[\"Fee Needed To Apply\"] = fees_needed_to_apply\n",
    "    \n",
    "        return cleaned_attributes\n",
    "\n",
    "    # Run the clean_up_the_fees function using the raw_attributes as input\n",
    "    cleaned_attributes = clean_up_the_fees(raw_attributes)\n",
    "\n",
    "    # Sort the cleaned_attributes in descending order of instance count\n",
    "    cleaned_attributes = dict(sorted(cleaned_attributes.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    # Collecting basic info from the soup content\n",
    "    def collect_basic_information(the_soup):\n",
    "        title_element = the_soup.find(\"span\", id=\"titletextonly\")\n",
    "        title = title_element.text.strip() if title_element else \"Title Not Found\"\n",
    "        \n",
    "        price_element = the_soup.find(\"span\", class_=\"price\")\n",
    "        price = price_element.text.strip() if price_element else \"Price Not Found\"\n",
    "        \n",
    "        housing_element = the_soup.find(\"span\", class_=\"housing\")\n",
    "        if housing_element:\n",
    "            try:\n",
    "                bedroom_info = housing_element.text.split(\"/\")[1].split(\"-\")[0].strip()\n",
    "                square_feet = housing_element.text.split(\"-\")[1].split(\"ft\")[0].strip()\n",
    "            except IndexError:\n",
    "                bedroom_info = \"Bedrooms Info Not Found\"\n",
    "                square_feet = \"Square Feet Not Found\"\n",
    "        else:\n",
    "            bedroom_info = \"Bedrooms Info Not Found\"\n",
    "            square_feet = \"Square Feet Not Found\"\n",
    "        \n",
    "        full_address_element = the_soup.find(\"h2\", class_=\"street-address\")\n",
    "        full_address = full_address_element.text.strip() if full_address_element else \"None listed\"\n",
    "    \n",
    "        return {\n",
    "            \"Title\": title,\n",
    "            \"Price\": price,\n",
    "            \"Bedrooms\": bedroom_info,\n",
    "            \"Square Feet\": square_feet,\n",
    "            \"Full Address\": full_address\n",
    "        }\n",
    "\n",
    "    def create_dataframe(links_and_soups):\n",
    "        all_entries = []\n",
    "        \n",
    "        for link, soup in links_and_soups.items():\n",
    "            basic_info = collect_basic_information(soup)\n",
    "            listing_attributes, fee_needed = process_attributes(soup)\n",
    "            new_row_data = {\n",
    "                **basic_info,\n",
    "                **{attr: 1 if attr in listing_attributes else 0 for attr in cleaned_attributes},\n",
    "                \"Fee Needed To Apply\": fee_needed,\n",
    "                \"date_added\": datetime.now().strftime('%Y-%m-%d')\n",
    "            }\n",
    "            \n",
    "            # Create a new entry ensuring all master attributes are included\n",
    "            complete_entry = create_new_entry(new_row_data)\n",
    "            all_entries.append(complete_entry)\n",
    "        \n",
    "        return pd.DataFrame(all_entries)\n",
    "\n",
    "    # Create the dataframe\n",
    "    todays_listings_df = create_dataframe(links_and_soups)\n",
    "\n",
    "    # Export data\n",
    "    todays_listings_df.to_csv('files/raw_daily_craigslist_listings.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1771515-af2c-46df-910e-94453974461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pull_craigslist_rates_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3ec666d-1ba6-425c-9c4d-1f96df3dafa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the URLs\n",
    "craigslist_base_url = 'https://losangeles.craigslist.org/search/santa-monica-ca/apa?lat=34.0315&lon=-118.461&max_bathrooms=1&max_bedrooms=1&min_bathrooms=1&min_bedrooms=1&postedToday=1&search_distance=3.6#search=1'\n",
    "craigslist_search_first_page_url = 'https://losangeles.craigslist.org/search/santa-monica-ca/apa?lat=34.0315&lon=-118.461&max_bathrooms=1&max_bedrooms=1&min_bathrooms=1&min_bedrooms=1&postedToday=1&search_distance=3.6#search=1~list~0~0'\n",
    "chrome_driver_path = '../Other_Material/chromedriver-mac-arm64/chromedriver'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc0e79fb-9175-48db-8a63-99ed0acad286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the access_beautiful_soup function\n",
    "def access_beautiful_soup(url):\n",
    "    # Call a get instance with the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Sleep in order to not overwhelm servers\n",
    "    time.sleep(5 + 10 * random.random())\n",
    "\n",
    "    # Find all the listings links on the page\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e2705f3-9011-46c2-af94-66a88e22da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return the number of posts at a given time\n",
    "def get_postings_count(website, path):\n",
    "    \n",
    "    # # prevent a window from opening in Selenium\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    \n",
    "    # set up the Chrome driver path for Selenium usage\n",
    "    service = Service(path)\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "    # Call a \"get\" instance of the initial Craigslist page to initialize Selenium\n",
    "    driver.get(website)\n",
    "\n",
    "    # Put in a function stopper to let the page render.\n",
    "    # 15 seconds should be plenty, but if the result is coming back as\n",
    "    # \"no results,\" the first troubleshoot would be to increase this time\n",
    "    # to see if that fixes it.\n",
    "    time.sleep(15)  \n",
    "\n",
    "    try:\n",
    "\n",
    "        # Use JavaScript to set up a script to return the postings count\n",
    "        postings_count_script = \"\"\"\n",
    "            var postingsDiv = document.querySelector('.cl-count-save-bar > div');\n",
    "            return postingsDiv ? postingsDiv.textContent : 'Postings count not found';\n",
    "        \"\"\"\n",
    "\n",
    "        # Execute the script to get the post count and return it\n",
    "        postings_count = driver.execute_script(postings_count_script)\n",
    "\n",
    "        # Quit Selenium\n",
    "        driver.quit()\n",
    "\n",
    "        # Return the postings count\n",
    "        return postings_count\n",
    "    except Exception as e:\n",
    "        print(f\"Error encountered: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "140cca79-94ff-42c2-846c-7294ad293d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the get_postings_count function\n",
    "postings_count = get_postings_count(craigslist_search_first_page_url, chrome_driver_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c1fb29f-e059-40f2-8b85-a552cc9aa9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 postings\n"
     ]
    }
   ],
   "source": [
    "# Check to see how many postings there are\n",
    "print(postings_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "831443e8-b771-42fc-b2b1-70d6d74539e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the number of pages for us to loop through\n",
    "def calculate_pages_from_postings(postings_count_str):\n",
    "    \n",
    "    # Remove commas and extract the numerical part of the string\n",
    "    num_postings = int(postings_count_str.replace(\" postings\", \"\").replace(\",\", \"\"))\n",
    "    \n",
    "    # 120 posts per page\n",
    "    postings_per_page = 120\n",
    "    \n",
    "    # Calculate the number of pages needed to display all postings, accounting for remainder\n",
    "    num_pages = -(-num_postings // postings_per_page)  \n",
    "    \n",
    "    return num_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb199d2b-9adc-40e3-b444-bd99c9a376be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages: 1\n"
     ]
    }
   ],
   "source": [
    "# Call the calculate_pages_from_postings function\n",
    "number_of_pages = calculate_pages_from_postings(postings_count)\n",
    "print(f\"Number of pages: {number_of_pages}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f05271a-2514-42f7-b66b-8c0fe314d171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the links from each of the pages\n",
    "def extract_listing_links(path, base_url, number_of_pages):\n",
    "    all_listing_links = []\n",
    "    \n",
    "    for page_number in range(number_of_pages):\n",
    "        page_url = f'{base_url}~list~{page_number}~0'\n",
    "        \n",
    "        # prevent a window from opening in Selenium\n",
    "        options = Options()\n",
    "        options.add_argument('--headless')\n",
    "        options.add_argument('--disable-gpu')\n",
    "        \n",
    "        # set up the Chrome driver path for Selenium usage\n",
    "        service = Service(path)\n",
    "        driver = webdriver.Chrome(service=service, options=options)\n",
    "        \n",
    "        driver.get(page_url)\n",
    "        \n",
    "        # Wait for the listings to be present\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"li.cl-search-result.cl-search-view-mode-list\"))\n",
    "        )\n",
    "        # Now that the page is loaded, find all the `a` tags within the listings\n",
    "        listing_links = [a.get_attribute('href') for a in driver.find_elements(By.CSS_SELECTOR, \"li.cl-search-result.cl-search-view-mode-list a\")]\n",
    "\n",
    "        all_listing_links.extend(listing_links)\n",
    "\n",
    "        driver.quit()\n",
    "        \n",
    "    return all_listing_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28e9a19b-a982-4c4b-8e77-df9ae404610c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n"
     ]
    }
   ],
   "source": [
    "all_links = extract_listing_links(chrome_driver_path, craigslist_base_url, number_of_pages)\n",
    "\n",
    "print(len(all_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32ebc3e9-217c-4fe6-8742-1670022d5a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link #1:  https://losangeles.craigslist.org/wst/apa/d/los-angeles-renovated-1br-apartment-in/7747671752.html\n",
      "Link #2:  https://losangeles.craigslist.org/wst/apa/d/santa-monica-situated-in-santa-monica/7747671511.html\n",
      "Link #3:  https://losangeles.craigslist.org/wst/apa/d/los-angeles-beautiful-one-bedroom/7747664102.html\n"
     ]
    }
   ],
   "source": [
    "print(f'Link #1: ',all_links[0])\n",
    "print(f'Link #2: ',all_links[1])\n",
    "print(f'Link #3: ',all_links[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e30bd09-9007-4dd6-bed3-992f5ed2dc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DataFrame\n",
    "df_columns = [\"Title\", \"Price\", \"Bedrooms\", \"Square Feet\", \"Full Address\"]\n",
    "todays_listings_df = pd.DataFrame(columns=df_columns)\n",
    "\n",
    "# Set the max columns to infinite so that we may view all of them\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60460ead-5f87-474c-97b1-c11f7f127a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_and_soups = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd64ecd5-252e-4e70-92cb-5ef0ed73777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to pair links with soup content\n",
    "def pair_links_and_soups(list_of_links):\n",
    "    for link in list_of_links:\n",
    "        the_soup = access_beautiful_soup(link)\n",
    "        links_and_soups[link] = the_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b13c32dd-df2c-4526-a8bb-a5493f7be1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_links_and_soups(all_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fa5f029-a6fa-4ac2-8323-743155b83210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n"
     ]
    }
   ],
   "source": [
    "print(len(links_and_soups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc87b3b2-d301-4d30-8ae6-475fb99419c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your master list of attributes\n",
    "master_attributes = [\n",
    "    \"Title\", \"Price\", \"Bedrooms\", \"Square Feet\", \"Full Address\", \"monthly\",\n",
    "    \"apartment\", \"cats are OK - purrr\", \"dogs are OK - wooof\", \"laundry on site\",\n",
    "    \"air conditioning\", \"off-street parking\", \"EV charging\", \"w/d in unit\",\n",
    "    \"carport\", \"no smoking\", \"attached garage\", \"detached garage\", \"laundry in bldg\",\n",
    "    \"Fee Needed To Apply\", \"wheelchair accessible\", \"no parking\", \"furnished\",\n",
    "    \"street parking\", \"no laundry on site\", \"house\", \"w/d hookups\", \"date_added\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5e36203-c7f6-4358-86be-4fc246d48979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to initialize the DataFrame with all required columns\n",
    "def initialize_dataframe():\n",
    "    # Create a DataFrame with all columns initialized to None or a suitable default\n",
    "    return pd.DataFrame(columns=master_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c89ecf5b-5482-4730-85b1-63bf0c5eaba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a new entry for the DataFrame\n",
    "def create_new_entry(data):\n",
    "    return {attr: data.get(attr, 0) if attr not in ['Title', \n",
    "                                                    'Price', \n",
    "                                                    'Bedrooms', \n",
    "                                                    'Square Feet', \n",
    "                                                    'Full Address', \n",
    "                                                    'date_added'] else data.get(attr, 0) for attr in master_attributes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c021279-9994-4449-994f-210e4151712b",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_attribute_counts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d5ee4ab-7ed3-4a2f-a742-f3ea567db2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the count_attributes_function to view all the attributes used in apartment listings\n",
    "def process_attributes(the_soup):\n",
    "    attribute_search = the_soup.find_all('div', class_='attr')\n",
    "    attributes = []\n",
    "    fee_needed = 0  # Initialize a flag for fees\n",
    "\n",
    "    fee_pattern = re.compile(r'\\b\\d+\\b')  # Regex to identify fee-related attributes\n",
    "\n",
    "    for listing in attribute_search:\n",
    "        value_span = listing.find('span', class_='valu')\n",
    "        if value_span:\n",
    "            attribute = value_span.text.strip()\n",
    "            global_attribute_counts[attribute] = global_attribute_counts.get(attribute, 0) + 1 \n",
    "            if fee_pattern.search(attribute):  # Check if attribute suggests a fee\n",
    "                fee_needed = 1\n",
    "            else:\n",
    "                attributes.append(attribute)  # Only add non-fee attributes to the list\n",
    "\n",
    "    return attributes, fee_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6e2526d-ff08-4c3a-8341-3428b83fbfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run process_attributes using the info in the links_and_soups dictionary\n",
    "for link, soup in links_and_soups.items():\n",
    "    attributes = process_attributes(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80b72ff7-b539-4187-95bc-ec5f4f912746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the object results in a variable called \"raw_attributes\" \n",
    "raw_attributes = global_attribute_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "735cc8fc-35a6-4444-bc78-0eec8f30acde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'monthly': 93,\n",
       " 'cats are OK - purrr': 85,\n",
       " 'apartment': 92,\n",
       " 'dogs are OK - wooof': 66,\n",
       " 'laundry in bldg': 32,\n",
       " 'off-street parking': 27,\n",
       " 'no smoking': 34,\n",
       " 'laundry on site': 35,\n",
       " 'attached garage': 27,\n",
       " 'air conditioning': 65,\n",
       " 'EV charging': 43,\n",
       " '$52': 10,\n",
       " 'carport': 26,\n",
       " 'wheelchair accessible': 27,\n",
       " 'w/d in unit': 26,\n",
       " '50.00': 2,\n",
       " '5%': 2,\n",
       " 'Shores Barrington, LLC': 2,\n",
       " '$40 per adult': 1,\n",
       " 'no parking': 5,\n",
       " 'furnished': 5,\n",
       " 'valet parking': 1,\n",
       " 'detached garage': 7,\n",
       " '35': 1,\n",
       " 'cottage/cabin': 1,\n",
       " 'Apply for rentals application forms': 1}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5eb4f5f7-dde6-4d03-9ff8-4c6c9f927ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to group together fee related attributes\n",
    "def clean_up_the_fees(attributes_dictionary):\n",
    "    \n",
    "    # Initialize a count for \"Fees Needed To Apply Key\"\n",
    "    fees_needed_to_apply = 0\n",
    "\n",
    "    # Set up a Regex to identify keys containing integers\n",
    "    # We will use the re package to do this\n",
    "    fee_pattern = re.compile(r'\\b\\d+\\b')\n",
    "\n",
    "    # Iterate through the dictionary, summing up counts for fee-related attributes\n",
    "    for key, value in raw_attributes.items():\n",
    "        if fee_pattern.search(key):\n",
    "            fees_needed_to_apply += value\n",
    "    \n",
    "    # Update the dictionary and add in a key called \"Fee Needed To Apply\"\n",
    "    cleaned_attributes = {key: value for key, value in raw_attributes.items() if not fee_pattern.search(key)}\n",
    "    cleaned_attributes[\"Fee Needed To Apply\"] = fees_needed_to_apply\n",
    "\n",
    "    return cleaned_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "543d4768-b5c7-4664-a526-3218bbb77434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the clean_up_the_fees function using the raw_attributes as input\n",
    "cleaned_attributes = clean_up_the_fees(raw_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cdcf218b-308b-4028-9cfe-f80b3f1e303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the cleaned_attributes in descending order of instance count\n",
    "cleaned_attributes = dict(sorted(cleaned_attributes.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f382a08-8a7c-4610-9327-d22752410a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_basic_information(the_soup):\n",
    "    title_element = the_soup.find(\"span\", id=\"titletextonly\")\n",
    "    title = title_element.text.strip() if title_element else \"Title Not Found\"\n",
    "    \n",
    "    price_element = the_soup.find(\"span\", class_=\"price\")\n",
    "    price = price_element.text.strip() if price_element else \"Price Not Found\"\n",
    "    \n",
    "    housing_element = the_soup.find(\"span\", class_=\"housing\")\n",
    "    if housing_element:\n",
    "        try:\n",
    "            bedroom_info = housing_element.text.split(\"/\")[1].split(\"-\")[0].strip()\n",
    "            square_feet = housing_element.text.split(\"-\")[1].split(\"ft\")[0].strip()\n",
    "        except IndexError:\n",
    "            bedroom_info = \"Bedrooms Info Not Found\"\n",
    "            square_feet = \"Square Feet Not Found\"\n",
    "    else:\n",
    "        bedroom_info = \"Bedrooms Info Not Found\"\n",
    "        square_feet = \"Square Feet Not Found\"\n",
    "    \n",
    "    full_address_element = the_soup.find(\"h2\", class_=\"street-address\")\n",
    "    full_address = full_address_element.text.strip() if full_address_element else \"None listed\"\n",
    "\n",
    "    return {\n",
    "        \"Title\": title,\n",
    "        \"Price\": price,\n",
    "        \"Bedrooms\": bedroom_info,\n",
    "        \"Square Feet\": square_feet,\n",
    "        \"Full Address\": full_address\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4167435-714d-47c1-a6f6-bcd646606d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(links_and_soups):\n",
    "    all_entries = []\n",
    "    \n",
    "    for link, soup in links_and_soups.items():\n",
    "        basic_info = collect_basic_information(soup)\n",
    "        listing_attributes, fee_needed = process_attributes(soup)\n",
    "        new_row_data = {\n",
    "            **basic_info,\n",
    "            **{attr: 1 if attr in listing_attributes else 0 for attr in cleaned_attributes},\n",
    "            \"Fee Needed To Apply\": fee_needed,\n",
    "            \"date_added\": datetime.now().strftime('%Y-%m-%d')\n",
    "        }\n",
    "        \n",
    "        # Create a new entry ensuring all master attributes are included\n",
    "        complete_entry = create_new_entry(new_row_data)\n",
    "        all_entries.append(complete_entry)\n",
    "    \n",
    "    return pd.DataFrame(all_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5535545f-640a-4ace-ba2f-64ccc8dcc82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>Square Feet</th>\n",
       "      <th>Full Address</th>\n",
       "      <th>monthly</th>\n",
       "      <th>apartment</th>\n",
       "      <th>cats are OK - purrr</th>\n",
       "      <th>dogs are OK - wooof</th>\n",
       "      <th>laundry on site</th>\n",
       "      <th>air conditioning</th>\n",
       "      <th>off-street parking</th>\n",
       "      <th>EV charging</th>\n",
       "      <th>w/d in unit</th>\n",
       "      <th>carport</th>\n",
       "      <th>no smoking</th>\n",
       "      <th>attached garage</th>\n",
       "      <th>detached garage</th>\n",
       "      <th>laundry in bldg</th>\n",
       "      <th>Fee Needed To Apply</th>\n",
       "      <th>wheelchair accessible</th>\n",
       "      <th>no parking</th>\n",
       "      <th>furnished</th>\n",
       "      <th>street parking</th>\n",
       "      <th>no laundry on site</th>\n",
       "      <th>house</th>\n",
       "      <th>w/d hookups</th>\n",
       "      <th>date_added</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Renovated 1BR Apartment in West LA - Hardwood ...</td>\n",
       "      <td>$2,515</td>\n",
       "      <td>1br</td>\n",
       "      <td>668</td>\n",
       "      <td>None listed</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-05-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Situated in Santa Monica!, 1/BD 1/BA, Hardwood...</td>\n",
       "      <td>$2,471</td>\n",
       "      <td>1br</td>\n",
       "      <td>382</td>\n",
       "      <td>1447 Lincoln Blvd, Santa Monica, CA 90401</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-05-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beautiful One Bedroom Apartment - The Lifestyl...</td>\n",
       "      <td>$3,405</td>\n",
       "      <td>1br</td>\n",
       "      <td>870</td>\n",
       "      <td>550 South Barrington Avenue, Los Angeles, CA 9...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-05-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Magnificent luxury building. 1 bed, 1 ba, 496 ...</td>\n",
       "      <td>$2,895</td>\n",
       "      <td>1br</td>\n",
       "      <td>496</td>\n",
       "      <td>3644 Overland Ave, Los Angeles, CA 90034</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-05-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Magnificent amenities. Great location. Secure ...</td>\n",
       "      <td>$3,255</td>\n",
       "      <td>1br</td>\n",
       "      <td>516</td>\n",
       "      <td>3644 Overland Ave, Los Angeles, CA 90034</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-05-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title   Price Bedrooms  \\\n",
       "0  Renovated 1BR Apartment in West LA - Hardwood ...  $2,515      1br   \n",
       "1  Situated in Santa Monica!, 1/BD 1/BA, Hardwood...  $2,471      1br   \n",
       "2  Beautiful One Bedroom Apartment - The Lifestyl...  $3,405      1br   \n",
       "3  Magnificent luxury building. 1 bed, 1 ba, 496 ...  $2,895      1br   \n",
       "4  Magnificent amenities. Great location. Secure ...  $3,255      1br   \n",
       "\n",
       "  Square Feet                                       Full Address  monthly  \\\n",
       "0         668                                        None listed        1   \n",
       "1         382          1447 Lincoln Blvd, Santa Monica, CA 90401        1   \n",
       "2         870  550 South Barrington Avenue, Los Angeles, CA 9...        1   \n",
       "3         496           3644 Overland Ave, Los Angeles, CA 90034        1   \n",
       "4         516           3644 Overland Ave, Los Angeles, CA 90034        1   \n",
       "\n",
       "   apartment  cats are OK - purrr  dogs are OK - wooof  laundry on site  \\\n",
       "0          1                    1                    1                0   \n",
       "1          1                    1                    0                1   \n",
       "2          1                    1                    1                1   \n",
       "3          1                    1                    1                1   \n",
       "4          1                    1                    1                0   \n",
       "\n",
       "   air conditioning  off-street parking  EV charging  w/d in unit  carport  \\\n",
       "0                 0                   1            0            0        0   \n",
       "1                 1                   0            1            0        0   \n",
       "2                 0                   0            0            0        0   \n",
       "3                 0                   0            0            0        1   \n",
       "4                 1                   0            1            1        1   \n",
       "\n",
       "   no smoking  attached garage  detached garage  laundry in bldg  \\\n",
       "0           1                0                0                1   \n",
       "1           0                1                0                0   \n",
       "2           0                1                0                0   \n",
       "3           0                0                0                0   \n",
       "4           1                0                0                0   \n",
       "\n",
       "   Fee Needed To Apply  wheelchair accessible  no parking  furnished  \\\n",
       "0                    0                      0           0          0   \n",
       "1                    0                      0           0          0   \n",
       "2                    0                      0           0          0   \n",
       "3                    1                      1           0          0   \n",
       "4                    1                      1           0          0   \n",
       "\n",
       "   street parking  no laundry on site  house  w/d hookups  date_added  \n",
       "0               0                   0      0            0  2024-05-17  \n",
       "1               0                   0      0            0  2024-05-17  \n",
       "2               0                   0      0            0  2024-05-17  \n",
       "3               0                   0      0            0  2024-05-17  \n",
       "4               0                   0      0            0  2024-05-17  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the dataframe\n",
    "todays_listings_df = create_dataframe(links_and_soups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d7831d8-e1ce-4771-8e6e-8bf24f148736",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'todays_listings_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtodays_listings_df\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/files/raw_daily_craigslist_listings.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'todays_listings_df' is not defined"
     ]
    }
   ],
   "source": [
    "todays_listings_df.to_csv('/files/raw_daily_craigslist_listings.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421a7f98-cc24-4d96-b7a8-131d39dbfcf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
