{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10af196b-3d82-497b-a46f-8e801dcc9b10",
   "metadata": {},
   "source": [
    "# Data Pull"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bab6e3-3178-4530-a62f-e26fb157b1b0",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dda57bc1-cdbe-41bc-bfdb-d0648a11623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4291330-f456-40ff-b56e-109a6aa6c0c7",
   "metadata": {},
   "source": [
    "## Perform Web Scrape from Craigslist in Los Angeles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7e9028-28e2-49d1-8d56-95061842cfb4",
   "metadata": {},
   "source": [
    "**A Note on the Default Search**\n",
    "\n",
    "The default starting page will have certain characteristics already standardized for the purposes of this project. I have narrowed the focus to only 1 bedroom, 1 bathroom apartments. There is also a specific map area being used. The map view is an area centered around Santa Monica, and encompasses the West Los Angeles region north of Manahattan Beach and south of Pacific Palisades. This area contains a high density of apartments, giving us a steady supply of data to pull.\n",
    "\n",
    "This pulls many results, and isolates two big cost factors in the forthcoming regression equation. This allows us to better view the effects of engineered features, which we will perform later. \n",
    "\n",
    "Our goal here is to cater the data science insights to me first with an eye towards scaling to a potential use case by anybody. Thus, while we will engineer the data infrastructure with an eye towards scaling the data quantity and features, we want to narrow the insights to be useful to at least one person (myself) before we expand further. This lets us behave pragmatically within the time constraints of a 7-week project. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9563c747-ec42-4b1a-81dc-d557a61f475e",
   "metadata": {},
   "source": [
    "First, let's declare global variables that will be used in our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df2541a3-38be-4430-a239-ee79738e7234",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Global Variables ##\n",
    "\n",
    "craigslist_base_url = 'https://losangeles.craigslist.org/search/santa-monica-ca/apa?lat=34.0315&lon=-118.461&max_bathrooms=1&max_bedrooms=1&min_bathrooms=1&min_bedrooms=1&postal=90095&search_distance=3.6#search=1'\n",
    "craigslist_search_first_page_url = 'https://losangeles.craigslist.org/search/santa-monica-ca/apa?lat=34.0315&lon=-118.461&max_bathrooms=1&max_bedrooms=1&min_bathrooms=1&min_bedrooms=1&postal=90095&search_distance=3.6#search=1~list~0~0'\n",
    "chrome_driver_path = '../Other_Material/chromedriver-mac-arm64/chromedriver'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50ec4ce-5b79-4bbc-96a7-1183c0c9321f",
   "metadata": {},
   "source": [
    "Next, let's proceed with implementing our Selenium code to get the total listings amount. We write a function called \"get_postings_count\" that takes in the two arguments \"website\" and \"path\" and returns the post count. We need to use JavaScript here, because the post count is loaded dynamically into the webpage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54513ff2-acb8-4480-9222-a086b40c1d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return the number of posts at a given time\n",
    "def get_postings_count(website, path):\n",
    "    \n",
    "    # prevent a window from opening in Selenium\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    \n",
    "    # set up the Chrome driver path for Selenium usage\n",
    "    service = Service(path)\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "    # Call a \"get\" instance of the initial Craigslist page to initialize Selenium\n",
    "    driver.get(website)\n",
    "\n",
    "    # Use a waiting period to make sure all the elements load for Selenium to inspect\n",
    "    wait = WebDriverWait(driver, 10)  # Wait for up to 10 seconds\n",
    "\n",
    "    try:\n",
    "        # Wait for the specific element to be present before executing the script\n",
    "        postings_count_element = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, '.cl-count-save-bar > div')))\n",
    "\n",
    "        # Use JavaScript to set up a script to return the postings count\n",
    "        postings_count_script = \"\"\"\n",
    "            var postingsDiv = document.querySelector('.cl-count-save-bar > div');\n",
    "            return postingsDiv ? postingsDiv.textContent : 'Postings count not found';\n",
    "        \"\"\"\n",
    "\n",
    "        # Execute the script to get the post count and return it\n",
    "        postings_count = driver.execute_script(postings_count_script)\n",
    "        return postings_count\n",
    "    finally:\n",
    "        # Exits Selenium\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51254b18-808f-42ac-9888-462009d47dd9",
   "metadata": {},
   "source": [
    "Let's call the function now to get the postings count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1e06641-4dd2-45d3-9dd9-4984f920f3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the get_postings_count function\n",
    "postings_count = get_postings_count(craigslist_search_first_page_url, chrome_driver_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24c6798-5d22-40b0-81b9-42868e090c84",
   "metadata": {},
   "source": [
    "Finally, let's print the amount of posts to see what we are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89ff4a5a-74a6-4381-8c8c-6e5d26eb9d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,353 postings\n"
     ]
    }
   ],
   "source": [
    "# Check to see how many postings there are\n",
    "print(postings_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f38f78-84c5-4c5d-8b51-d912fbc05c54",
   "metadata": {},
   "source": [
    "We can now use the post count to get the number of pages to loop through. There are 120 posts per page, so we want to extract the post count and divide it by 120."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d2173c4-61f7-460b-974b-e4ca9c3400bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the number of pages for us to loop through\n",
    "def calculate_pages_from_postings(postings_count_str):\n",
    "    \n",
    "    # Remove commas and extract the numerical part of the string\n",
    "    num_postings = int(postings_count_str.replace(\" postings\", \"\").replace(\",\", \"\"))\n",
    "    \n",
    "    # 120 posts per page\n",
    "    postings_per_page = 120\n",
    "    \n",
    "    # Calculate the number of pages needed to display all postings, accounting for remainder\n",
    "    num_pages = -(-num_postings // postings_per_page)  \n",
    "    \n",
    "    return num_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1a101ea-d031-43e6-a033-a51ced126038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages: 20\n"
     ]
    }
   ],
   "source": [
    "# Call the calculate_pages_from_postings function\n",
    "number_of_pages = calculate_pages_from_postings(postings_count)\n",
    "print(f\"Number of pages: {number_of_pages}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f114a6e-e32e-4ff5-a502-709fa8145890",
   "metadata": {},
   "source": [
    "Next, we write a function to extract the links from each of the pages. We do this by \n",
    "\n",
    "1. initializing a list\n",
    "2. looping through the number of pages\n",
    "3. finding all the 'li' tags within page that use the class 'cl-static-search-result'\n",
    "4. finding the 'a' tags within the 'li' tags, which contain the link to the individual listing\n",
    "5. appending these links to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9000ca2b-8a3d-403e-a996-fc4433872e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the extract_listings_links function\n",
    "def extract_listings_links(number_of_pages):\n",
    "    \n",
    "    # Initialize a list to store the links\n",
    "    listings_links = []\n",
    "\n",
    "    # Iterate through the number of pages\n",
    "    for i in range(number_of_pages):  \n",
    "\n",
    "        # Use the page number to get the webpages containing the listings\n",
    "        page_number = i\n",
    "        page_url = f'{craigslist_base_url}~list~{page_number}~0'\n",
    "\n",
    "        # Call a get instance with the URL\n",
    "        response = requests.get(page_url)\n",
    "\n",
    "        # Sleep in order to not overwhelm servers\n",
    "        time.sleep(5 + 10 * random.random())\n",
    "\n",
    "        # Find all the listings links on the page\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Look for all 'li' tags with the class 'cl-static-search-result'\n",
    "        listings = soup.find_all('li', class_='cl-static-search-result')\n",
    "\n",
    "        # Loop through all the listings and append links to the list\n",
    "        for listing in listings:\n",
    "            a_tag = listing.find('a', href=True)\n",
    "            if a_tag:\n",
    "                listings_links.append(a_tag['href'])\n",
    "\n",
    "    return listings_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4818f2c7-cd85-4e0e-9d7b-840d91ae53b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the extract_listings_links function and store the returned list in the 'all_links' variable\n",
    "all_links = extract_listings_links(number_of_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261360ec-1f4b-4ac8-aaa5-fff7d7080612",
   "metadata": {},
   "source": [
    "Let's check out the \"all_links\" list to see the extraction was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "229b01ff-8ef6-4130-9b8a-4051bc724375",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200\n"
     ]
    }
   ],
   "source": [
    "print(len(all_links))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b1e1b3-0e53-4288-859f-91ae173706d4",
   "metadata": {},
   "source": [
    "We see that there is content within the all_links list. Next, let's get a sample of three of the links to ensure we pulled what we wanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90e8f55b-2f07-4a91-94b4-0208faebf590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link #1:  https://losangeles.craigslist.org/wst/apa/d/venice-bedroom-in-marina-del-rey-quartz/7726576879.html\n",
      "Link #2:  https://losangeles.craigslist.org/wst/apa/d/los-angeles-bedroom-ba-in-west-la/7726576204.html\n",
      "Link #3:  https://losangeles.craigslist.org/wst/apa/d/los-angeles-westwood-bedroom-bath/7726575683.html\n"
     ]
    }
   ],
   "source": [
    "print(f'Link #1: ',all_links[0])\n",
    "print(f'Link #2: ',all_links[1])\n",
    "print(f'Link #3: ',all_links[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c8d8ac-9841-4513-8f78-c797537edc52",
   "metadata": {},
   "source": [
    "**Let us dive into working with the data within each listing link.**\n",
    "\n",
    "We will start out by using just one of the links to do a single data pull. Once we do this, we can plan to write a function that will loop through all of the links in the all_links list.\n",
    "\n",
    "First, we will use the requests and BeautifulSoup packages again to access the webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffd974a3-4fef-46a7-869f-f4e2129d35be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call a get instance from the \"requests\" package using the URL\n",
    "link_response = requests.get('https://losangeles.craigslist.org/wst/apa/d/los-angeles-live-at-palms-caribbean/7724486915.html')\n",
    "\n",
    "# Sleep in order to not overwhelm servers\n",
    "time.sleep(5 + 10 * random.random())\n",
    "\n",
    "# Find all the listings links on the page\n",
    "link_soup = BeautifulSoup(link_response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb2219a-0725-4a15-9085-5cd30f7207c7",
   "metadata": {},
   "source": [
    "Below we isolate some of the pieces of information we want to use in the upcoming structured data frame we will put together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80c5b237-a6bd-4e1f-b63d-7574bcf12bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = link_soup.find(\"span\", id=\"titletextonly\").text.strip()\n",
    "price = link_soup.find(\"span\", class_=\"price\").text.strip()\n",
    "bedroom_info = link_soup.find(\"span\", class_=\"housing\").text.split(\"/\")[1].split(\"-\")[0].strip()\n",
    "square_feet = link_soup.find(\"span\", class_=\"housing\").text.split(\"-\")[1].split(\"ft\")[0].strip()\n",
    "full_address = link_soup.find(\"h2\", class_=\"street-address\").text.strip()\n",
    "\n",
    "attribute_search = link_soup.find_all('div', class_='attr')\n",
    "attributes = []\n",
    "for listing in attribute_search:\n",
    "    value_span = listing.find('span', class_='valu')\n",
    "    attribute = value_span.text.strip()\n",
    "    attributes.append(attribute)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c5207b-8278-4f8a-9ba9-b85024f3673f",
   "metadata": {},
   "source": [
    "Let us pause here to see what we have pulled from the listing we are testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdf48f7d-7ee5-46dd-8e6b-c661c92ca982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Live at Palms Caribbean Apts 1 Bedroom 1 BA with Fridge, 2 Weeks Free!\n",
      "$1,900\n",
      "1br\n",
      "550\n",
      "3258 Overland Avenue, Palms, CA 90034\n",
      "['monthly', 'air conditioning', 'cats are OK - purrr', 'apartment', 'laundry on site', 'off-street parking']\n"
     ]
    }
   ],
   "source": [
    "print(title)\n",
    "print(price)\n",
    "print(bedroom_info)\n",
    "print(square_feet)\n",
    "print(full_address)\n",
    "print(attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d15219d-88d5-436f-98ef-e23a7bb0017e",
   "metadata": {},
   "source": [
    "Now let's create a sample dataframe using the information we have so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c603fa7-414d-43f8-8330-8891d8ee3574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas DataFrame\n",
    "sample_df = pd.DataFrame({\n",
    "    \"Title\": [title],\n",
    "    \"Price\": [price],\n",
    "    \"Bedrooms\": [bedroom_info],\n",
    "    \"Square Feet\": [square_feet],\n",
    "    \"Full Address\": [full_address],\n",
    "    \"Attributes\": [attributes]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bc224d0-ad82-4807-8932-67bf0f9fd735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>Square Feet</th>\n",
       "      <th>Full Address</th>\n",
       "      <th>Attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Live at Palms Caribbean Apts 1 Bedroom 1 BA wi...</td>\n",
       "      <td>$1,900</td>\n",
       "      <td>1br</td>\n",
       "      <td>550</td>\n",
       "      <td>3258 Overland Avenue, Palms, CA 90034</td>\n",
       "      <td>[monthly, air conditioning, cats are OK - purr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title   Price Bedrooms  \\\n",
       "0  Live at Palms Caribbean Apts 1 Bedroom 1 BA wi...  $1,900      1br   \n",
       "\n",
       "  Square Feet                           Full Address  \\\n",
       "0         550  3258 Overland Avenue, Palms, CA 90034   \n",
       "\n",
       "                                          Attributes  \n",
       "0  [monthly, air conditioning, cats are OK - purr...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0423aa-8fec-4226-b29c-df9fe929e80a",
   "metadata": {},
   "source": [
    "Next, we work on extracting the content body of the listing. The content body will contain information in a less structured way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6b259be-5bb0-4dbf-ab79-85bf8dd55db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the section body content located within the \"postingbody\" id\n",
    "section_body = link_soup.find('section', id='postingbody')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44e7dc6-ad30-46bd-9c5b-f83fefa415f1",
   "metadata": {},
   "source": [
    "As a starting point, it will be easiest to use the body content as a large string, since each listing's content format and information will vary considerably. Thus, below we use BeautifulSoup's text search \".text\" feature to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e253e8b-1349-481e-8ee0-53693fa24689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QR Code Link to This Post\n",
      "\n",
      "\n",
      "\n",
      "2 Weeks Free Off the 2nd Month With A 12 Month Lease\n",
      "\n",
      "\n",
      "Virtual Tour Unit 5819: https://my.matterport.com/show/?m=Q9v2nFtipfU\n",
      "\n",
      "Welcome to Palms Caribbean Apartments!\n",
      "\n",
      "Palms Caribbean Apartments is centrally located in the Palms/West Los Angeles/Culver City Adj area near shops and restaurants on Venice Blvd., and just a few minutes from the 405/10 freeways. We have apartments ranging from 1-3 bedrooms. Amenities include a pool, parking, and laundry on site. Our apartment amenities include stainless steel kitchen appliances in select units, vinyl plank flooring, and more. Come check us out today!\n",
      "\n",
      "\n",
      " Your New Apartment Home Features: \n",
      "\n",
      "- Vinyl Plank Flooring \n",
      "- Granite Countertops \n",
      "- Air Conditioning \n",
      "- Disposal \n",
      "- Stainless Steel Appliances (In Select Units) \n",
      "- Ceiling Fan(s) \n",
      "- Carpeting \n",
      "- Refrigerator \n",
      "- Gas Stove \n",
      "\n",
      "\n",
      "Property Features: \n",
      "\n",
      "- Uncovered Parking \n",
      "- Pool \n",
      "- Laundry On Site \n",
      "\n",
      "\n",
      "Pet Policy: \n",
      "\n",
      "Cats Welcome. Additional Fees and Deposit May Apply. \n",
      "Call for Details and Restrictions.\n",
      "\n",
      "\n",
      "\n",
      "3258-3264 Overland Los Angeles, CA \n",
      "\n",
      "Contact Us:\n",
      "\n",
      "\n",
      "Call: show contact info\n",
      "\n",
      "Visit us Online:  http://www.palmscaribbeanapts.com?rcstdid=MzM%3d-dkCsfkCKtXI%3d\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Surrounding Cities and Neighborhoods: Culver City, Santa Monica, Westwood, Pacific Western University, Notre Fame Academy ES, Palms ES, Palms Middle School, Junior HS, 405, 110, 10, Mathias Botanical Garden, Ballona Creek Trail - Ballona Wetlands Ecological Reserve Access, Zimmer Children's Museum, Mar Vista Recreation Center, Palms Recreation Center, Culver Center, One Westside Shopping Center, Culver City Town Plaza, Ralphs, Vons, Trader Joe's, Sugar Fish, Town and Country Mall, Sor Tino, Baltaire, California Pizza Kitchen, Vespertine, Seventy7 Lounge\n"
     ]
    }
   ],
   "source": [
    "# Extract all text within the section as one string\n",
    "description_text = section_body.text.strip()\n",
    "\n",
    "print(description_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
