{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10af196b-3d82-497b-a46f-8e801dcc9b10",
   "metadata": {},
   "source": [
    "# Data Pull"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bab6e3-3178-4530-a62f-e26fb157b1b0",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dda57bc1-cdbe-41bc-bfdb-d0648a11623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4291330-f456-40ff-b56e-109a6aa6c0c7",
   "metadata": {},
   "source": [
    "## Perform Web Scrape from Craigslist in Los Angeles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7e9028-28e2-49d1-8d56-95061842cfb4",
   "metadata": {},
   "source": [
    "**A Note on the Default Search**\n",
    "\n",
    "The default starting page will have certain characteristics already standardized for the purposes of this project. I have narrowed the focus to only 1 bedroom, 1 bathroom apartments. There is also a specific map area being used. The map view is an area centered around Santa Monica, and encompasses the West Los Angeles region north of Manahattan Beach and south of Pacific Palisades. This area contains a high density of apartments, giving us a steady supply of data to pull.\n",
    "\n",
    "This strategy pulls many results and isolates two big cost factors in the forthcoming regression equation. This allows us to better view the effects of engineered features, which we will perform later. \n",
    "\n",
    "Our goal here is to cater the data science insights to me (the author) first with an eye towards scaling to a potential use case by anyone. Thus, while we will engineer the data infrastructure with an eye towards scaling the data quantity and features, for now we want to narrow the insights to be useful to at least one person (myself) before we expand further. This lets us behave pragmatically within the time constraints of a 7-week project. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9563c747-ec42-4b1a-81dc-d557a61f475e",
   "metadata": {},
   "source": [
    "#### First, we declare global variables that will be used in our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df2541a3-38be-4430-a239-ee79738e7234",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Global Variables ##\n",
    "\n",
    "# craigslist_base_url = 'https://losangeles.craigslist.org/search/santa-monica-ca/apa?lat=34.0315&lon=-118.461&max_bathrooms=1&max_bedrooms=1&min_bathrooms=1&min_bedrooms=1&postal=90095&search_distance=3.6#search=1'\n",
    "# craigslist_search_first_page_url = 'https://losangeles.craigslist.org/search/santa-monica-ca/apa?lat=34.0315&lon=-118.461&max_bathrooms=1&max_bedrooms=1&min_bathrooms=1&min_bedrooms=1&postal=90095&search_distance=3.6#search=1~list~0~0'\n",
    "craigslist_base_url = 'https://losangeles.craigslist.org/search/santa-monica-ca/apa?lat=34.019&lon=-118.4724&max_bathrooms=1&max_bedrooms=1&min_bathrooms=1&min_bedrooms=1&postal=90095&search_distance=0.7#search=1'\n",
    "craigslist_search_first_page_url = 'https://losangeles.craigslist.org/search/santa-monica-ca/apa?lat=34.019&lon=-118.4724&max_bathrooms=1&max_bedrooms=1&min_bathrooms=1&min_bedrooms=1&postal=90095&search_distance=0.7#search=1~list~0~0'\n",
    "chrome_driver_path = '../Other_Material/chromedriver-mac-arm64/chromedriver'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c631c0b-caf7-4d35-a213-2d8d2de7259b",
   "metadata": {},
   "source": [
    "#### We will be using BeautifulSoup to access URLs in this notebook, so we write a function to perform this operation now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6580d9f-841b-42e1-9e74-12767cae04f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the access_beautiful_soup function\n",
    "def access_beautiful_soup(url):\n",
    "    # Call a get instance with the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Sleep in order to not overwhelm servers\n",
    "    time.sleep(5 + 10 * random.random())\n",
    "\n",
    "    # Find all the listings links on the page\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50ec4ce-5b79-4bbc-96a7-1183c0c9321f",
   "metadata": {},
   "source": [
    "#### Before we access the URLs of the listings, we need to find out how many results are in the search query. \n",
    "\n",
    "For the search in the area of Los Angeles we are doing, the number is typically around 2400 at any given time (posts expire after 30 days). However, we want to construct the application with an eye towards scaling, so we need to make the infrastructure flexible for different result amounts.\n",
    "\n",
    "Since this information is not accessible via BeautifulSoup based on the way the Craigslist HTML structure is set up, we need to use Selenium. \n",
    "\n",
    "We now proceed with implementing the Selenium code to get the total listings amount. We write a function called \"get_postings_count\" that takes in the two arguments \"website\" and \"path\" and returns the post count. We need to use JavaScript here, because the post count is loaded dynamically into the webpage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54513ff2-acb8-4480-9222-a086b40c1d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return the number of posts at a given time\n",
    "def get_postings_count(website, path):\n",
    "    \n",
    "    # prevent a window from opening in Selenium\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    \n",
    "    # set up the Chrome driver path for Selenium usage\n",
    "    service = Service(path)\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "    # Call a \"get\" instance of the initial Craigslist page to initialize Selenium\n",
    "    driver.get(website)\n",
    "\n",
    "    # Use a waiting period of up to 10 seconds to make sure all the elements load for Selenium to inspect\n",
    "    wait = WebDriverWait(driver, 10)  \n",
    "\n",
    "    try:\n",
    "        # Wait for the specific element to be present before executing the script\n",
    "        postings_count_element = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, '.cl-count-save-bar > div')))\n",
    "\n",
    "        # Use JavaScript to set up a script to return the postings count\n",
    "        postings_count_script = \"\"\"\n",
    "            var postingsDiv = document.querySelector('.cl-count-save-bar > div');\n",
    "            return postingsDiv ? postingsDiv.textContent : 'Postings count not found';\n",
    "        \"\"\"\n",
    "\n",
    "        # Execute the script to get the post count and return it\n",
    "        postings_count = driver.execute_script(postings_count_script)\n",
    "        return postings_count\n",
    "    finally:\n",
    "        # Exits Selenium\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51254b18-808f-42ac-9888-462009d47dd9",
   "metadata": {},
   "source": [
    "#### Let's call the function now to get the postings count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1e06641-4dd2-45d3-9dd9-4984f920f3b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Call the get_postings_count function\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m postings_count \u001b[38;5;241m=\u001b[39m \u001b[43mget_postings_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcraigslist_search_first_page_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchrome_driver_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m, in \u001b[0;36mget_postings_count\u001b[0;34m(website, path)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# set up the Chrome driver path for Selenium usage\u001b[39;00m\n\u001b[1;32m     10\u001b[0m service \u001b[38;5;241m=\u001b[39m Service(path)\n\u001b[0;32m---> 11\u001b[0m driver \u001b[38;5;241m=\u001b[39m \u001b[43mwebdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChrome\u001b[49m\u001b[43m(\u001b[49m\u001b[43mservice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Call a \"get\" instance of the initial Craigslist page to initialize Selenium\u001b[39;00m\n\u001b[1;32m     14\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(website)\n",
      "File \u001b[0;32m~/ENTER/lib/python3.11/site-packages/selenium/webdriver/chrome/webdriver.py:45\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[0;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     42\u001b[0m service \u001b[38;5;241m=\u001b[39m service \u001b[38;5;28;01mif\u001b[39;00m service \u001b[38;5;28;01melse\u001b[39;00m Service()\n\u001b[1;32m     43\u001b[0m options \u001b[38;5;241m=\u001b[39m options \u001b[38;5;28;01mif\u001b[39;00m options \u001b[38;5;28;01melse\u001b[39;00m Options()\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbrowser_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDesiredCapabilities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHROME\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbrowserName\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvendor_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgoog\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ENTER/lib/python3.11/site-packages/selenium/webdriver/chromium/webdriver.py:61\u001b[0m, in \u001b[0;36mChromiumDriver.__init__\u001b[0;34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     52\u001b[0m executor \u001b[38;5;241m=\u001b[39m ChromiumRemoteConnection(\n\u001b[1;32m     53\u001b[0m     remote_server_addr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mservice_url,\n\u001b[1;32m     54\u001b[0m     browser_name\u001b[38;5;241m=\u001b[39mbrowser_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m     ignore_proxy\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39m_ignore_local_proxy,\n\u001b[1;32m     58\u001b[0m )\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecutor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquit()\n",
      "File \u001b[0;32m~/ENTER/lib/python3.11/site-packages/selenium/webdriver/remote/webdriver.py:208\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[0;34m(self, command_executor, keep_alive, file_detector, options)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_authenticator_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_client()\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcapabilities\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ENTER/lib/python3.11/site-packages/selenium/webdriver/remote/webdriver.py:292\u001b[0m, in \u001b[0;36mWebDriver.start_session\u001b[0;34m(self, capabilities)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new session with the desired capabilities.\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03m:Args:\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;124;03m - capabilities - a capabilities dict to start the session with.\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    291\u001b[0m caps \u001b[38;5;241m=\u001b[39m _create_caps(capabilities)\n\u001b[0;32m--> 292\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNEW_SESSION\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaps\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcaps \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcapabilities\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/ENTER/lib/python3.11/site-packages/selenium/webdriver/remote/webdriver.py:345\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m    343\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[0;32m--> 345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[0;32m~/ENTER/lib/python3.11/site-packages/selenium/webdriver/remote/remote_connection.py:302\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    300\u001b[0m trimmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trim_large_entries(params)\n\u001b[1;32m    301\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, command_info[\u001b[38;5;241m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[0;32m--> 302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ENTER/lib/python3.11/site-packages/selenium/webdriver/remote/remote_connection.py:322\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[0;34m(self, method, url, body)\u001b[0m\n\u001b[1;32m    319\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[0;32m--> 322\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/ENTER/lib/python3.11/site-packages/urllib3/request.py:78\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[1;32m     75\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[1;32m     76\u001b[0m     )\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_encode_body\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43murlopen_kw\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ENTER/lib/python3.11/site-packages/urllib3/request.py:170\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mupdate(headers)\n\u001b[1;32m    168\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[0;32m--> 170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ENTER/lib/python3.11/site-packages/urllib3/poolmanager.py:376\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    374\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 376\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[0;32m~/ENTER/lib/python3.11/site-packages/urllib3/connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 714\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ENTER/lib/python3.11/site-packages/urllib3/connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    461\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    462\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/ENTER/lib/python3.11/site-packages/urllib3/connectionpool.py:461\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 461\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/ENTER/lib/python3.11/http/client.py:1378\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1378\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1379\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1380\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/ENTER/lib/python3.11/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/ENTER/lib/python3.11/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/ENTER/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Call the get_postings_count function\n",
    "postings_count = get_postings_count(craigslist_search_first_page_url, chrome_driver_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24c6798-5d22-40b0-81b9-42868e090c84",
   "metadata": {},
   "source": [
    "#### Finally, we print the amount of posts to see how many we are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89ff4a5a-74a6-4381-8c8c-6e5d26eb9d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 postings\n"
     ]
    }
   ],
   "source": [
    "# Check to see how many postings there are\n",
    "print(postings_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f38f78-84c5-4c5d-8b51-d912fbc05c54",
   "metadata": {},
   "source": [
    "#### We can now use the post count to get the number of pages to loop through when we extract the listings. \n",
    "\n",
    "There are 120 posts per page, so we want to extract the post count and divide it by 120."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d2173c4-61f7-460b-974b-e4ca9c3400bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the number of pages for us to loop through\n",
    "def calculate_pages_from_postings(postings_count_str):\n",
    "    \n",
    "    # Remove commas and extract the numerical part of the string\n",
    "    num_postings = int(postings_count_str.replace(\" postings\", \"\").replace(\",\", \"\"))\n",
    "    \n",
    "    # 120 posts per page\n",
    "    postings_per_page = 120\n",
    "    \n",
    "    # Calculate the number of pages needed to display all postings, accounting for remainder\n",
    "    num_pages = -(-num_postings // postings_per_page)  \n",
    "    \n",
    "    return num_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1a101ea-d031-43e6-a033-a51ced126038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages: 1\n"
     ]
    }
   ],
   "source": [
    "# Call the calculate_pages_from_postings function\n",
    "number_of_pages = calculate_pages_from_postings(postings_count)\n",
    "print(f\"Number of pages: {number_of_pages}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f114a6e-e32e-4ff5-a502-709fa8145890",
   "metadata": {},
   "source": [
    "#### Next, we write a function to extract the links from each of the pages. We do this by: \n",
    "\n",
    "1. initializing a list\n",
    "2. looping through the number of pages\n",
    "3. finding all the 'li' tags within page that use the class 'cl-static-search-result'\n",
    "4. finding the 'a' tags within the 'li' tags, which contain the link to the individual listing\n",
    "5. appending these links to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "526bf5aa-2c13-40d8-bdd6-160c351656ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_listing_links(path, base_url, number_of_pages):\n",
    "    all_listing_links = []\n",
    "    \n",
    "    for page_number in range(number_of_pages):\n",
    "        page_url = f'{base_url}~list~{page_number}~0'\n",
    "        \n",
    "        # prevent a window from opening in Selenium\n",
    "        options = Options()\n",
    "        options.add_argument('--headless')\n",
    "        options.add_argument('--disable-gpu')\n",
    "        \n",
    "        # set up the Chrome driver path for Selenium usage\n",
    "        service = Service(path)\n",
    "        driver = webdriver.Chrome(service=service, options=options)\n",
    "        \n",
    "        driver.get(page_url)\n",
    "        # Wait for the listings to be present\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"li.cl-search-result.cl-search-view-mode-list\"))\n",
    "        )\n",
    "        # Now that the page is loaded, find all the `a` tags within the listings\n",
    "        listing_links = [a.get_attribute('href') for a in driver.find_elements(By.CSS_SELECTOR, \"li.cl-search-result.cl-search-view-mode-list a\")]\n",
    "\n",
    "        all_listing_links.extend(listing_links)\n",
    "\n",
    "        driver.quit()\n",
    "        \n",
    "    return all_listing_links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d45417-9b5b-4071-9f6d-4d336fa102f0",
   "metadata": {},
   "source": [
    "## NOTE TO SELF: DO NOT RE-RUN THE BELOW CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "796be205-a37d-4ba7-9c23-e9ef9167c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_links = extract_listing_links(chrome_driver_path, craigslist_base_url, number_of_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64af09d5-8ab8-4483-aca9-5751c318e3cd",
   "metadata": {},
   "source": [
    "## NOTE TO SELF: DO NOT RE-RUN THE ABOVE CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261360ec-1f4b-4ac8-aaa5-fff7d7080612",
   "metadata": {},
   "source": [
    "#### Let's check out the \"all_links\" list to see the extraction was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "229b01ff-8ef6-4130-9b8a-4051bc724375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "print(len(all_links))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b1e1b3-0e53-4288-859f-91ae173706d4",
   "metadata": {},
   "source": [
    "#### We see that there is content within the all_links list. \n",
    "\n",
    "Let us also get a sample of three of the links to ensure we pulled what we wanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90e8f55b-2f07-4a91-94b4-0208faebf590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link #1:  https://losangeles.craigslist.org/wst/apa/d/santa-monica-refrigerator-hardwood/7728203084.html\n",
      "Link #2:  https://losangeles.craigslist.org/wst/apa/d/santa-monica-new-renovated-interior/7728136256.html\n",
      "Link #3:  https://losangeles.craigslist.org/wst/apa/d/santa-monica-remodeled-cottage-style/7728056080.html\n"
     ]
    }
   ],
   "source": [
    "print(f'Link #1: ',all_links[0])\n",
    "print(f'Link #2: ',all_links[1])\n",
    "print(f'Link #3: ',all_links[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c8d8ac-9841-4513-8f78-c797537edc52",
   "metadata": {},
   "source": [
    "#### We now dive into working with the data within each listing link.\n",
    "\n",
    "First, we set up a dataframe containing basic column information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "59268f23-ad4e-4bca-9a5b-829e0d7514c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DataFrame\n",
    "df_columns = [\"Title\", \"Price\", \"Bedrooms\", \"Square Feet\", \"Full Address\"]\n",
    "listings_df = pd.DataFrame(columns=df_columns)\n",
    "\n",
    "# Set the max columns to infinite so that we may view all of them\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ff0463-05c0-4dd4-9ef8-697bcbb29f39",
   "metadata": {},
   "source": [
    "## We declare an object called \"links_and_soups\" to pair each link with its BeautifulSoup content.\n",
    "\n",
    "This is a lengthy process, due to the fact that we have random sleep intervals between each time we access BeautifulSoup. \n",
    "\n",
    "We need to do this because the soup content will contain the information we want, so we need the soup content for each of the links. \n",
    "\n",
    "We start by declaring the object that will hold the links and soups as key value pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbdb3d1-2991-418f-8326-1377adffa0cb",
   "metadata": {},
   "source": [
    "## NOTE TO SELF DO NOT RUN BELOW CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6b021f4f-ce69-4b12-8e7b-3e56423c79d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv(\"../Data/linksnsoups.csv\", header=None, names=['link', 'soup_string'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7918256f-c3e0-458e-a46d-83c705ad128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_and_soups = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d3d87625-5763-420d-b713-7e0835a7c89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2395 entries.\n"
     ]
    }
   ],
   "source": [
    "# Convert string back to BeautifulSoup objects and populate the dictionary\n",
    "for index, row in df.iterrows():\n",
    "    soup_object = BeautifulSoup(row['soup_string'], 'html.parser')  # Assuming 'html.parser' was used initially\n",
    "    links_and_soups[row['link']] = soup_object\n",
    "\n",
    "print(f\"Loaded {len(links_and_soups)} entries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90f1d38-14d3-4712-bd19-6cf4bcf9314a",
   "metadata": {},
   "source": [
    "## NOTE TO SELF DO NOT RUN ABOVE CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b9a7d8-d2f1-4fc3-82b0-077a2099ce51",
   "metadata": {},
   "source": [
    "#### We write a function for pairing the links with their soup content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7882c75d-d3fa-4ebc-acb8-f8274c82a5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to pair links with soup content\n",
    "# def pair_links_and_soups(list_of_links):\n",
    "#     for link in list_of_links:\n",
    "#         the_soup = access_beautiful_soup(link)\n",
    "#         links_and_soups[link] = the_soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d8eca8-cefd-4997-9b28-824fbe806c4e",
   "metadata": {},
   "source": [
    "## NOTE TO SELF DO NOT RUN BELOW CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33159583-d65c-4bd5-aa79-1c3c407062b5",
   "metadata": {},
   "source": [
    "We run the function using the links that were pulled previously.\n",
    "\n",
    "**NOTE: This can take a long time. For example, 2300 links took 7.5 hours**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5012d4ee-f5ac-498d-8e5a-36e5605ecc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair_links_and_soups(all_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8404b71f-9d3f-4c57-a19d-62ba01e1b539",
   "metadata": {},
   "source": [
    "## NOTE TO SELF DO NOT RUN ABOVE CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb0a1a5-97d9-4826-b463-f17188efe217",
   "metadata": {},
   "source": [
    "#### Let's check to see if the links and soups object was successfully populated with data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a7803c42-9714-43f3-9147-4c10bc085f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2395\n"
     ]
    }
   ],
   "source": [
    "print(len(links_and_soups))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f86efbe-7455-4714-8fe7-57986f70e753",
   "metadata": {},
   "source": [
    "#### Next, we begin the process of creating boolean values for different attributes.\n",
    "\n",
    "Each listing contains different attributes that the poster uses to convey information about a property and market it. While there is a lot of overlap between listings, we need to see all of the options. To do this, we initialize a dictionary called \"full_attribute_counts,\" then add unique values and count them. Ultimately, we want to create columns with these values and use boolean values \"1\" or \"0\" meaning \"present\" or \"not present\" in the listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "eb89e2f5-b8c1-443d-9369-8df2b1f5b6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_attribute_counts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "213fbb51-8b4a-46c2-a74f-3cf7ea2fba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the count_attributes_function to view all the attributes used in apartment listings\n",
    "def process_attributes(the_soup):\n",
    "    attribute_search = the_soup.find_all('div', class_='attr')\n",
    "    attributes = []\n",
    "    fee_needed = 0  # Initialize a flag for fees\n",
    "\n",
    "    fee_pattern = re.compile(r'\\b\\d+\\b')  # Regex to identify fee-related attributes\n",
    "\n",
    "    for listing in attribute_search:\n",
    "        value_span = listing.find('span', class_='valu')\n",
    "        if value_span:\n",
    "            attribute = value_span.text.strip()\n",
    "            global_attribute_counts[attribute] = global_attribute_counts.get(attribute, 0) + 1 \n",
    "            if fee_pattern.search(attribute):  # Check if attribute suggests a fee\n",
    "                fee_needed = 1\n",
    "            else:\n",
    "                attributes.append(attribute)  # Only add non-fee attributes to the list\n",
    "\n",
    "    return attributes, fee_needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37949ad7-80a4-44e5-94cb-01e7aaf62311",
   "metadata": {},
   "source": [
    "#### Below we run the process_attributes function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "217d74ec-fb7d-4ffe-a524-83878054208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run process_attributes using the info in the links_and_soups dictionary\n",
    "for link, soup in links_and_soups.items():\n",
    "    attributes = process_attributes(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6072f62c-6110-4aaa-9b51-26d79db91982",
   "metadata": {},
   "source": [
    "#### Let's take a look at all the attributes that were pulled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "067ba5ae-4632-4304-a880-334e751edc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the object results in a variable called \"raw_attributes\" \n",
    "raw_attributes = global_attribute_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0a94e1ef-c380-4ab3-869b-0dafd7b9e2de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'monthly': 2323,\n",
       " 'air conditioning': 1339,\n",
       " 'cats are OK - purrr': 1823,\n",
       " 'apartment': 2315,\n",
       " 'laundry on site': 1392,\n",
       " 'off-street parking': 817,\n",
       " 'dogs are OK - wooof': 1425,\n",
       " 'carport': 501,\n",
       " 'laundry in bldg': 371,\n",
       " 'w/d in unit': 532,\n",
       " 'detached garage': 394,\n",
       " 'attached garage': 431,\n",
       " 'wheelchair accessible': 354,\n",
       " 'no smoking': 498,\n",
       " 'EV charging': 684,\n",
       " 'no parking': 140,\n",
       " 'furnished': 83,\n",
       " '$52': 146,\n",
       " 'house': 6,\n",
       " 'street parking': 42,\n",
       " '$49.50': 146,\n",
       " '$49': 1,\n",
       " 'None': 2,\n",
       " 'CRE Inc': 2,\n",
       " '$30': 1,\n",
       " '50$': 1,\n",
       " '25.00': 1,\n",
       " 'no laundry on site': 27,\n",
       " '$30 application fee per applicant': 2,\n",
       " '$50 Dollars per applicant.': 2,\n",
       " 'NO BROKER FEE': 2,\n",
       " 'PRIVATE OWNER': 1,\n",
       " 'REMAX': 1,\n",
       " '$45.00 Application Screening Fee Per Adult': 11,\n",
       " '40': 1,\n",
       " '40 per person': 2,\n",
       " 'valet parking': 2,\n",
       " 'w/d hookups': 5,\n",
       " '$45': 3,\n",
       " 'daily': 3,\n",
       " '$45 Application Fee': 3,\n",
       " '$50': 1,\n",
       " '39.99': 2,\n",
       " '$42.50': 2,\n",
       " '$26 per adult': 2,\n",
       " 'www.conradpm.com $45': 1,\n",
       " '$35': 2,\n",
       " 'condo': 2,\n",
       " 'duplex': 3,\n",
       " '45.00': 1,\n",
       " '$25 Application Fee': 2,\n",
       " '$25 per application': 2,\n",
       " '$40 non refundable application fee and credit check': 6,\n",
       " 'cottage/cabin': 1,\n",
       " 'weekly': 1,\n",
       " '$35 per adult': 1,\n",
       " 'Parking space fee is negotiable': 1,\n",
       " '$25.00': 1,\n",
       " '$40 Per Adult': 1,\n",
       " '40.00 credit check fee per adult': 1,\n",
       " '$40 per adult': 5,\n",
       " '$40 application process': 1,\n",
       " '$40.00 PER APPILCANT': 2,\n",
       " '$50.00': 4,\n",
       " '50': 2,\n",
       " '$45 per applicant': 1,\n",
       " '$49 per applicant': 1}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc70451e-464d-47b4-b5e4-0a8c58d4a918",
   "metadata": {},
   "source": [
    "#### We see a lot of overlap but also noise to clean up\n",
    "We see there is a high proportion of overlap with \"monthly\" being the most common item found. Outside the most common, there is some noise to clean up. Looking closer, we see that the noise is mostly made up of application and credit check fees. To clean this up, we can remove all of this and simply group all of these into a key called \"Fee Needed To Apply\". Let's write a function that will clean up listings with fee information. This will do a very simple check: if there is an attribute with an integer in it, then it will be categorized as a fee. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fbc02842-274e-4e4e-92b4-d40fe5f88edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to group together fee related attributes\n",
    "def clean_up_the_fees(attributes_dictionary):\n",
    "    \n",
    "    # Initialize a count for \"Fees Needed To Apply Key\"\n",
    "    fees_needed_to_apply = 0\n",
    "\n",
    "    # Set up a Regex to identify keys containing integers\n",
    "    # We will use the re package to do this\n",
    "    fee_pattern = re.compile(r'\\b\\d+\\b')\n",
    "\n",
    "    # Iterate through the dictionary, summing up counts for fee-related attributes\n",
    "    for key, value in raw_attributes.items():\n",
    "        if fee_pattern.search(key):\n",
    "            fees_needed_to_apply += value\n",
    "    \n",
    "    # Update the dictionary and add in a key called \"Fee Needed To Apply\"\n",
    "    cleaned_attributes = {key: value for key, value in raw_attributes.items() if not fee_pattern.search(key)}\n",
    "    cleaned_attributes[\"Fee Needed To Apply\"] = fees_needed_to_apply\n",
    "\n",
    "    return cleaned_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "107305f9-650d-4bfe-bf02-2f7041391351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the clean_up_the_fees function using the raw_attributes as input\n",
    "cleaned_attributes = clean_up_the_fees(raw_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "df2b7df6-ef19-4d02-ae67-57e69f21f54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the cleaned_attributes in descending order of instance count\n",
    "cleaned_attributes = dict(sorted(cleaned_attributes.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91115afd-80cb-4d06-8c37-8c7989d40883",
   "metadata": {},
   "source": [
    "#### Inspecting the cleaned attributes dictionary.\n",
    "\n",
    "We see the fee related material is now grouped into one key called \"Fee Needed To Apply,\" such that we answer the question of whether or not a fee is needed for an application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e48d73b8-ef3e-40f7-bbf6-2964b7a3f47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'monthly': 2323,\n",
       " 'apartment': 2315,\n",
       " 'cats are OK - purrr': 1823,\n",
       " 'dogs are OK - wooof': 1425,\n",
       " 'laundry on site': 1392,\n",
       " 'air conditioning': 1339,\n",
       " 'off-street parking': 817,\n",
       " 'EV charging': 684,\n",
       " 'w/d in unit': 532,\n",
       " 'carport': 501,\n",
       " 'no smoking': 498,\n",
       " 'attached garage': 431,\n",
       " 'detached garage': 394,\n",
       " 'laundry in bldg': 371,\n",
       " 'Fee Needed To Apply': 361,\n",
       " 'wheelchair accessible': 354,\n",
       " 'no parking': 140,\n",
       " 'furnished': 83,\n",
       " 'street parking': 42,\n",
       " 'no laundry on site': 27,\n",
       " 'house': 6,\n",
       " 'w/d hookups': 5,\n",
       " 'daily': 3,\n",
       " 'duplex': 3,\n",
       " 'None': 2,\n",
       " 'CRE Inc': 2,\n",
       " 'NO BROKER FEE': 2,\n",
       " 'valet parking': 2,\n",
       " 'condo': 2,\n",
       " 'PRIVATE OWNER': 1,\n",
       " 'REMAX': 1,\n",
       " 'cottage/cabin': 1,\n",
       " 'weekly': 1,\n",
       " 'Parking space fee is negotiable': 1}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d585fc-0c80-42e6-b280-c671762fc7c4",
   "metadata": {},
   "source": [
    "#### We will have some noise that we don't know the meaning of. \n",
    "\n",
    "Many of the attributes seem to be one-off items that are unique to one or two posts. Let us get rid of the ones with less than 5 instances, with \"w/d hookups\" as our cut-off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "902cc188-4193-459d-867b-a2bc2ddc5bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out attributes with less than 10 instance counts\n",
    "filtered_attributes = {key: value for key, value in cleaned_attributes.items() if value >= 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "300ed90e-a604-48d4-a22c-4f35953dc968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'monthly': 2323,\n",
       " 'apartment': 2315,\n",
       " 'cats are OK - purrr': 1823,\n",
       " 'dogs are OK - wooof': 1425,\n",
       " 'laundry on site': 1392,\n",
       " 'air conditioning': 1339,\n",
       " 'off-street parking': 817,\n",
       " 'EV charging': 684,\n",
       " 'w/d in unit': 532,\n",
       " 'carport': 501,\n",
       " 'no smoking': 498,\n",
       " 'attached garage': 431,\n",
       " 'detached garage': 394,\n",
       " 'laundry in bldg': 371,\n",
       " 'Fee Needed To Apply': 361,\n",
       " 'wheelchair accessible': 354,\n",
       " 'no parking': 140,\n",
       " 'furnished': 83,\n",
       " 'street parking': 42,\n",
       " 'no laundry on site': 27,\n",
       " 'house': 6,\n",
       " 'w/d hookups': 5}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a28e68dc-ed92-403c-b11a-0875f5801090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_basic_information(the_soup):\n",
    "    title_element = the_soup.find(\"span\", id=\"titletextonly\")\n",
    "    title = title_element.text.strip() if title_element else \"Title Not Found\"\n",
    "    \n",
    "    price_element = the_soup.find(\"span\", class_=\"price\")\n",
    "    price = price_element.text.strip() if price_element else \"Price Not Found\"\n",
    "    \n",
    "    housing_element = the_soup.find(\"span\", class_=\"housing\")\n",
    "    if housing_element:\n",
    "        try:\n",
    "            bedroom_info = housing_element.text.split(\"/\")[1].split(\"-\")[0].strip()\n",
    "            square_feet = housing_element.text.split(\"-\")[1].split(\"ft\")[0].strip()\n",
    "        except IndexError:\n",
    "            bedroom_info = \"Bedrooms Info Not Found\"\n",
    "            square_feet = \"Square Feet Not Found\"\n",
    "    else:\n",
    "        bedroom_info = \"Bedrooms Info Not Found\"\n",
    "        square_feet = \"Square Feet Not Found\"\n",
    "    \n",
    "    full_address_element = the_soup.find(\"h2\", class_=\"street-address\")\n",
    "    full_address = full_address_element.text.strip() if full_address_element else \"None listed\"\n",
    "\n",
    "    return title, price, bedroom_info, square_feet, full_address\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fe7cc134-4327-42ee-bb72-3dd8a1a5a2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the count_attributes_function to view all the attributes used in apartment listings\n",
    "# def create_dataframe(links_and_soups, listings_df):\n",
    "#     localized_df = listings_df.copy()\n",
    "    \n",
    "#     for link, soup in links_and_soups.items():\n",
    "#         title, price, bedroom_info, square_feet, full_address = collect_basic_information(soup)\n",
    "#         listing_attributes, fee_needed = process_attributes(soup)\n",
    "        \n",
    "#         new_row_data = {\"Title\": title, \"Price\": price, \"Bedrooms\": bedroom_info, \"Square Feet\": square_feet, \"Full Address\": full_address}\n",
    "        \n",
    "#         # For each attribute in filtered_attributes, add to new_row_data with 1 or 0\n",
    "#         for attribute in filtered_attributes.keys():\n",
    "#             new_row_data[attribute] = 1 if attribute in listing_attributes else 0\n",
    "\n",
    "#         # Convert new_row_data to a DataFrame row and concat to localized_df\n",
    "#         new_row_df = pd.DataFrame([new_row_data])\n",
    "#         localized_df = pd.concat([localized_df, new_row_df], ignore_index=True)\n",
    "    \n",
    "#     return localized_df\n",
    "\n",
    "\n",
    "def create_dataframe(links_and_soups, listings_df):\n",
    "    localized_df = listings_df.copy()\n",
    "    \n",
    "    for link, soup in links_and_soups.items():\n",
    "        title, price, bedroom_info, square_feet, full_address = collect_basic_information(soup)\n",
    "        listing_attributes, fee_needed = process_attributes(soup)  # Capture fee_needed flag here\n",
    "        \n",
    "        # Start with basic info\n",
    "        new_row_data = {\n",
    "            \"Title\": title,\n",
    "            \"Price\": price,\n",
    "            \"Bedrooms\": bedroom_info,\n",
    "            \"Square Feet\": square_feet,\n",
    "            \"Full Address\": full_address,\n",
    "        }\n",
    "        \n",
    "        # For each attribute in filtered_attributes, add to new_row_data with 1 or 0\n",
    "        for attribute in filtered_attributes.keys():\n",
    "            new_row_data[attribute] = 1 if attribute in listing_attributes else 0\n",
    "        \n",
    "        # Add \"Fee Needed To Apply\" after processing filtered_attributes\n",
    "        new_row_data[\"Fee Needed To Apply\"] = fee_needed\n",
    "\n",
    "        # Convert new_row_data to a DataFrame row and concat to localized_df\n",
    "        new_row_df = pd.DataFrame([new_row_data])\n",
    "        localized_df = pd.concat([localized_df, new_row_df], ignore_index=True)\n",
    "    \n",
    "    return localized_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0b91413e-1140-444e-87a4-da6a88689681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now call the updated function\n",
    "listings_df = create_dataframe(links_and_soups, listings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "288767b0-bac8-43af-8956-655369433835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>Square Feet</th>\n",
       "      <th>Full Address</th>\n",
       "      <th>monthly</th>\n",
       "      <th>apartment</th>\n",
       "      <th>cats are OK - purrr</th>\n",
       "      <th>dogs are OK - wooof</th>\n",
       "      <th>laundry on site</th>\n",
       "      <th>air conditioning</th>\n",
       "      <th>off-street parking</th>\n",
       "      <th>EV charging</th>\n",
       "      <th>w/d in unit</th>\n",
       "      <th>carport</th>\n",
       "      <th>no smoking</th>\n",
       "      <th>attached garage</th>\n",
       "      <th>detached garage</th>\n",
       "      <th>laundry in bldg</th>\n",
       "      <th>Fee Needed To Apply</th>\n",
       "      <th>wheelchair accessible</th>\n",
       "      <th>no parking</th>\n",
       "      <th>furnished</th>\n",
       "      <th>street parking</th>\n",
       "      <th>no laundry on site</th>\n",
       "      <th>house</th>\n",
       "      <th>w/d hookups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Title Not Found</td>\n",
       "      <td>Price Not Found</td>\n",
       "      <td>Bedrooms Info Not Found</td>\n",
       "      <td>Square Feet Not Found</td>\n",
       "      <td>None listed</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 Bedroom in Marina Del Rey -Quartz Counters -...</td>\n",
       "      <td>$3,295</td>\n",
       "      <td>1br</td>\n",
       "      <td>750</td>\n",
       "      <td>415 Washington Boulevard, Venice, CA 90292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 Bedroom 1 BA in West L.A. | Hardwood Style F...</td>\n",
       "      <td>$2,250</td>\n",
       "      <td>1br</td>\n",
       "      <td>700</td>\n",
       "      <td>None listed</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lease TODAY, Save BIG! One Month FREE Rent Offer!</td>\n",
       "      <td>$2,700</td>\n",
       "      <td>1br</td>\n",
       "      <td>590</td>\n",
       "      <td>11411 Rochester Avenue, Los Angeles, CA 90025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 Bedroom in the Heart of Venice* Plank Floors...</td>\n",
       "      <td>$2,895</td>\n",
       "      <td>1br</td>\n",
       "      <td>750</td>\n",
       "      <td>237 Fourth Avenue, Venice, CA 90291</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title            Price  \\\n",
       "0                                    Title Not Found  Price Not Found   \n",
       "1  1 Bedroom in Marina Del Rey -Quartz Counters -...           $3,295   \n",
       "2  1 Bedroom 1 BA in West L.A. | Hardwood Style F...           $2,250   \n",
       "3  Lease TODAY, Save BIG! One Month FREE Rent Offer!           $2,700   \n",
       "4  1 Bedroom in the Heart of Venice* Plank Floors...           $2,895   \n",
       "\n",
       "                  Bedrooms            Square Feet  \\\n",
       "0  Bedrooms Info Not Found  Square Feet Not Found   \n",
       "1                      1br                    750   \n",
       "2                      1br                    700   \n",
       "3                      1br                    590   \n",
       "4                      1br                    750   \n",
       "\n",
       "                                    Full Address  monthly  apartment  \\\n",
       "0                                    None listed      0.0        0.0   \n",
       "1     415 Washington Boulevard, Venice, CA 90292      1.0        1.0   \n",
       "2                                    None listed      1.0        1.0   \n",
       "3  11411 Rochester Avenue, Los Angeles, CA 90025      1.0        1.0   \n",
       "4            237 Fourth Avenue, Venice, CA 90291      1.0        1.0   \n",
       "\n",
       "   cats are OK - purrr  dogs are OK - wooof  laundry on site  \\\n",
       "0                  0.0                  0.0              0.0   \n",
       "1                  1.0                  0.0              1.0   \n",
       "2                  1.0                  0.0              1.0   \n",
       "3                  1.0                  1.0              1.0   \n",
       "4                  0.0                  0.0              0.0   \n",
       "\n",
       "   air conditioning  off-street parking  EV charging  w/d in unit  carport  \\\n",
       "0               0.0                 0.0          0.0          0.0      0.0   \n",
       "1               1.0                 1.0          0.0          0.0      0.0   \n",
       "2               0.0                 1.0          0.0          0.0      0.0   \n",
       "3               0.0                 0.0          0.0          0.0      1.0   \n",
       "4               0.0                 1.0          0.0          0.0      0.0   \n",
       "\n",
       "   no smoking  attached garage  detached garage  laundry in bldg  \\\n",
       "0         0.0              0.0              0.0              0.0   \n",
       "1         0.0              0.0              0.0              0.0   \n",
       "2         0.0              0.0              0.0              0.0   \n",
       "3         0.0              0.0              0.0              0.0   \n",
       "4         0.0              0.0              0.0              1.0   \n",
       "\n",
       "   Fee Needed To Apply  wheelchair accessible  no parking  furnished  \\\n",
       "0                  0.0                    0.0         0.0        0.0   \n",
       "1                  0.0                    0.0         0.0        0.0   \n",
       "2                  0.0                    0.0         0.0        0.0   \n",
       "3                  0.0                    0.0         0.0        0.0   \n",
       "4                  0.0                    0.0         0.0        0.0   \n",
       "\n",
       "   street parking  no laundry on site  house  w/d hookups  \n",
       "0             0.0                 0.0    0.0          0.0  \n",
       "1             0.0                 0.0    0.0          0.0  \n",
       "2             0.0                 0.0    0.0          0.0  \n",
       "3             0.0                 0.0    0.0          0.0  \n",
       "4             0.0                 0.0    0.0          0.0  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "04886899-4c5c-4018-ab05-48eadb04695a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2395"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(listings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9f88134b-d523-4100-9449-d92d6f398fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_df.to_csv('../Data/craigslist_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
